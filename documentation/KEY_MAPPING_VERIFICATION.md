# Fairness Feature - Key Mapping Verification

## âœ… Key Mappings Verified

### 1. Backend Service â†’ Database (Python â†’ PostgreSQL)

**fairness.py returns:**
```python
{
    'fairness_metrics': {
        'demographic_parity_difference': float,
        'equal_opportunity_difference': float,
        'disparate_impact_ratio': float,
        'statistical_parity': float,
        'predictive_parity': float,
        'equalized_odds_difference': float,
        'overall_fairness_score': float
    },
    'group_metrics': [
        {
            'group': str,
            'sample_count': int,
            'accuracy': float,
            'precision': float,
            'recall': float,
            'f1_score': float,
            'true_positive_rate': float,
            'false_positive_rate': float,
            'positive_prediction_rate': float,
            'true_positives': int,
            'false_positives': int,
            'true_negatives': int,
            'false_negatives': int
        }
    ],
    'sensitive_attribute': str,
    'num_groups': int,
    'analysis_successful': bool
}
```

**evaluation.py saves to database:**
```python
eval_data = {
    "fairness_metrics": fairness_result.get("fairness_metrics"),  # JSONB
    "group_metrics": fairness_result.get("group_metrics"),        # JSONB array
    "sensitive_attribute": fairness_result.get("sensitive_attribute")  # TEXT
}
```

### 2. Database â†’ Frontend (PostgreSQL â†’ TypeScript)

**Supabase Query:**
```typescript
.select(`
  *,
  models:model_id(name),
  datasets:dataset_id(name)
`)
```

**Frontend Interfaces:**
```typescript
interface FairnessMetrics {
  demographic_parity_difference: number;
  equal_opportunity_difference: number;
  disparate_impact_ratio: number;
  statistical_parity: number;
  predictive_parity: number;
  equalized_odds_difference: number;
  overall_fairness_score: number;
}

interface GroupMetrics {
  group: string;
  accuracy: number;
  precision: number;
  recall: number;
  f1_score: number;
  true_positive_rate: number;
  false_positive_rate: number;
  positive_prediction_rate: number;
  sample_count: number;
}

interface Evaluation {
  id: string;
  model_id: string;
  dataset_id: string;
  model_type: string;
  meta_score: number;
  fairness_metrics?: FairnessMetrics;
  group_metrics?: GroupMetrics[];
  sensitive_attribute?: string;
  created_at: string;
  models?: {
    name: string;
  };
  datasets?: {
    name: string;
  };
}
```

## ğŸ”‘ Key Fixes Applied

### Issue 1: Model/Dataset Names
**Problem:** Frontend expected `model_name` and `dataset_name` directly on evaluation
**Solution:** Added JOIN query to fetch related model and dataset names
```typescript
// Before (WRONG):
model_name: string;
dataset_name: string;

// After (CORRECT):
models?: { name: string };
datasets?: { name: string };

// Usage:
evalItem.models?.name || 'Unknown Model'
evalItem.datasets?.name || 'Unknown Dataset'
```

### Issue 2: Unused Import
**Problem:** Imported `Database` type but not using it
**Solution:** Removed unused import

## ğŸ¯ Data Flow Verification

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. User runs evaluation with dataset containing sensitive  â”‚
â”‚    attribute (e.g., gender, race, age_group)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. Backend: evaluation.py detects sensitive attribute      â”‚
â”‚    - Looks for: gender, race, sex, age_group, ethnicity    â”‚
â”‚    - Falls back to categorical columns with few values     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3. Backend: fairness_engine.analyze_fairness()             â”‚
â”‚    - Computes 6 fairness metrics                           â”‚
â”‚    - Analyzes performance by demographic group             â”‚
â”‚    - Calculates overall fairness score                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. Backend: Saves to database (evaluations table)          â”‚
â”‚    - fairness_metrics: JSONB                               â”‚
â”‚    - group_metrics: JSONB array                            â”‚
â”‚    - sensitive_attribute: TEXT                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. Frontend: Fairness.tsx loads evaluations                â”‚
â”‚    - JOINs models and datasets tables for names            â”‚
â”‚    - Filters for evaluations with fairness_metrics         â”‚
â”‚    - Auto-selects most recent                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 6. Frontend: Displays fairness analysis                    â”‚
â”‚    - Overall score with color coding                       â”‚
â”‚    - Fairness metrics charts                               â”‚
â”‚    - Group comparison visualizations                       â”‚
â”‚    - Actionable recommendations                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ… All Keys Correctly Mapped

### Fairness Metrics Keys (Match 100%)
- âœ… demographic_parity_difference
- âœ… equal_opportunity_difference
- âœ… disparate_impact_ratio
- âœ… statistical_parity
- âœ… predictive_parity
- âœ… equalized_odds_difference
- âœ… overall_fairness_score

### Group Metrics Keys (Match 100%)
- âœ… group
- âœ… accuracy
- âœ… precision
- âœ… recall
- âœ… f1_score
- âœ… true_positive_rate
- âœ… false_positive_rate
- âœ… positive_prediction_rate
- âœ… sample_count

### Additional Backend Keys (Used Internally)
- true_positives
- false_positives
- true_negatives
- false_negatives
(These are computed but not displayed in frontend, available if needed)

### Evaluation Keys (Match 100%)
- âœ… id
- âœ… model_id
- âœ… dataset_id
- âœ… fairness_metrics
- âœ… group_metrics
- âœ… sensitive_attribute
- âœ… created_at
- âœ… models.name (via JOIN)
- âœ… datasets.name (via JOIN)

## ğŸ¨ Chart Data Transformations

### Bar Chart (Fairness Metrics)
```typescript
metricsChartData = Object.entries(fairnessMetrics)
  .filter(([key]) => key !== 'overall_fairness_score')
  .map(([key, value]) => ({
    name: formatMetricName(key),      // "Demographic Parity Difference"
    value: Math.abs(value),            // Absolute value for visualization
    rawValue: value,                   // Original value for tooltip
    interpretation: getMetricInterpretation(key, value)  // Fair/Moderate/Biased
  }))
```

### Line Chart (Group Comparison)
```typescript
groupComparisonData = groupMetrics.map(group => ({
  group: group.group,
  accuracy: group.accuracy * 100,    // Convert to percentage
  precision: group.precision * 100,
  recall: group.recall * 100,
  f1_score: group.f1_score * 100,
}))
```

### Radar Chart (Multi-Metric View)
```typescript
radarData = groupMetrics.map(group => ({
  metric: group.group,               // Group name as axis
  Accuracy: group.accuracy * 100,
  Precision: group.precision * 100,
  Recall: group.recall * 100,
  'F1 Score': group.f1_score * 100,
}))
```

## ğŸ” Type Safety

All interfaces are strongly typed with TypeScript:
- âœ… No `any` types in production code
- âœ… Optional chaining for nullable fields (`?.`)
- âœ… Fallback values for undefined data
- âœ… Type guards for data validation

## ğŸ“‹ Testing Checklist

Use this to verify key mappings:

- [ ] Database migration adds all 3 columns
- [ ] Backend returns fairness_metrics as object (not null)
- [ ] Backend returns group_metrics as array (not null)
- [ ] Backend saves sensitive_attribute name correctly
- [ ] Frontend fetches with JOIN for model/dataset names
- [ ] Frontend displays model Ã— dataset in selector
- [ ] Charts receive correct data format
- [ ] All metric keys render without undefined errors
- [ ] Group metrics table displays all columns
- [ ] Overall score calculates correctly (0-1 range)

## ğŸ‰ Status: All Keys Verified âœ…

No key mismatches found. The data flow from backend â†’ database â†’ frontend is consistent and type-safe.
